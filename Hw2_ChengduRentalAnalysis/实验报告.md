# HW2_成都租房数据分析与可视化

## 1 实验介绍

1. 以成都市租房数据统计作为案例,完成了一个基本数据分析过程:

- Pandas 读写操作
- 使用预处理技术过滤数据
- 使用 Matplotlib 库绘制图标实现可视化
- 基于数据进行分析



## 2 实验目的

- 利用爬虫技术从链家网站上爬取成都市租房价格情况,将数据爬下储存到CSV文件中.后续再对数据读取,预处理清洗,可视化分析等操作.
- 进而可以直观的对成都租房价格,区域分布等等数据有个更深入的了解,帮助人们根据自己的条件,选择租房的最优解.



## 3 实验流程

1. 爬取数据
   - 使用 selenium 库从链家网上爬取成都市租房价格信息,存储到 CSV 文件中
2. 数据可视化
   - 利用pandas库读取文件
   - 进行数据预处理,过滤数据
   - 使用 Matplotlib Seaborn 库进行数据可视化操作
3. 数据分析



## 4 实验过程

### 4.1 爬取数据

- 通过 selenium 库从链家网站上爬取租房价格信息,将数据保存在 CSV 文件中

- 爬虫代码如下:

  - 部分代码由 deepseek 生成

  ```python
  from selenium import webdriver
  from selenium.webdriver.common.by import By
  import csv
  import time
  
  # 初始化CSV文件
  csv_file = open('shanghai_rent.csv', 'w', newline='', encoding='utf-8')
  csv_writer = csv.writer(csv_file)
  csv_writer.writerow(['标题', '价格', '面积', '区域', '链接'])
  
  # 初始化Selenium WebDriver
  driver = webdriver.Chrome()
  
  # 爬取多页数据
  for page in range(1, 101):  # 假设爬取前100页
      url = f'https://sh.lianjia.com/zufang/pg{page}/'
      print(f'正在爬取第{page}页: {url}')
  
      driver.get(url)
      time.sleep(2)  # 等待页面加载
  
      # 查找租房信息
      rent_items = driver.find_elements(By.CSS_SELECTOR, 'div.content__list--item')
  
      for item in rent_items:
          try:
              title = item.find_element(By.CSS_SELECTOR, 'p.content__list--item--title').text.strip()
              price = item.find_element(By.CSS_SELECTOR, 'span.content__list--item-price').text.strip()
              area = item.find_element(By.CSS_SELECTOR, 'p.content__list--item--des').text.strip().split('/')[1].strip()
              region = item.find_element(By.CSS_SELECTOR, 'p.content__list--item--des').text.strip().split('/')[0].strip()
              link = item.find_element(By.CSS_SELECTOR, 'a.content__list--item--aside').get_attribute('href')
  
              csv_writer.writerow([title, price, area, region, link])
          except Exception as e:
              print(f'解析错误: {e}')
  
      # 每页爬取后暂停一段时间
      time.sleep(2)
  
  # 关闭CSV文件
  csv_file.close()
  
  # 关闭WebDriver
  driver.quit()
  print('爬取完成，数据已保存到shanghai_rent.csv')
  ```

  - 具体信息如下所示:

![image-20241013213645851](../../../../../../Library/Application Support/typora-user-images/image-20241013213645851.png)



### 4.2 数据可视化

#### 4.2.1 读取数据

- 利用 pandas 库读取数据

![image-20241013214621736](../../../../../../Library/Application Support/typora-user-images/image-20241013214621736.png)

![image-20241013214640236](../../../../../../Library/Application Support/typora-user-images/image-20241013214640236.png)







#### 4.2.2 数据预处理

1. 删除重复值、空值

![image-20241013230825585](../../../../../../Library/Application Support/typora-user-images/image-20241013230825585.png)

![image-20241013230849544](../../../../../../Library/Application Support/typora-user-images/image-20241013230849544.png)



2. 检查数据类型
   - 这对后面的数据分析很重要

![image-20241013230957793](../../../../../../Library/Application Support/typora-user-images/image-20241013230957793.png)



3. 删除价格是区间范围行的数据,这一点很重要,便于后续的数据分析,其实可以取区间中值,但图方便删除也问题不大

![image-20241013231123033](../../../../../../Library/Application Support/typora-user-images/image-20241013231123033.png)



#### 4.3 数据分析

1. 统计数据集中每个区域的租房信息数量
   - 但是由于成都的数据爬取下来之后没有按城市的区县划分,所以这个分析内容意义不大

![image-20241013231206451](../../../../../../Library/Application Support/typora-user-images/image-20241013231206451.png)



2. 划分面积区间并可视化

![image-20241013231404778](../../../../../../Library/Application Support/typora-user-images/image-20241013231404778.png)

![image-20241013231417873](../../../../../../Library/Application Support/typora-user-images/image-20241013231417873.png)





3. 划分价格区间并可视化

![image-20241013231512941](../../../../../../Library/Application Support/typora-user-images/image-20241013231512941.png)

![image-20241013231522408](../../../../../../Library/Application Support/typora-user-images/image-20241013231522408.png)



4. 划分每平方米平均租金分布并可视化

![image-20241013231816887](../../../../../../Library/Application Support/typora-user-images/image-20241013231816887.png)

![image-20241013231827526](../../../../../../Library/Application Support/typora-user-images/image-20241013231827526.png)



## 5 实验总结

### 5.1 遇到的困难

1. 在爬取数据的过程中,如果在短时间内多次访问服务器的话,会被拦截,导致爬虫失败

2. matplotlib seaborn 库在macOS系统上的中文字体显示出了问题,由于近期才换了macOS,还在配置环境和习惯中,所以这方面花费了一些时间

   - 参考以下博客:https://gitcode.com/Resource-Bundle-Collection/d2bea/overview?utm_source=pan_gitcode&index=bottom&type=card&webUrl&isLogin=1

     ![image-20241013214511392](../../../../../../Library/Application Support/typora-user-images/image-20241013214511392.png)

3. 实验过程中python解释器出现了问题,搜了很多教程也没得到解决,最后通过重启 Pycharm 问题自然就解决了.

4. word 书写实验报告还是感觉不是很高效,可能是我使用word不太熟练,感觉使用 Markdown 或 LaTeX 更加高效,排版更加美观.



### 5.2 实验结果

1. Hw2所有代码和相关文件全部上传到 Github 仓库: https://github.com/KaiHaverz/dataScience_learningRecord